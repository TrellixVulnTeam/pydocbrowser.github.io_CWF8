<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
          "DTD/xhtml1-strict.dtd">
<html>
  

  <head>
    
    <title>scrapy.robotstxt.RerpRobotParser</title>
    <meta name="generator" content="pydoctor 22.2.2.dev0"> 
        
    </meta>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=0.75" />
    <link rel="stylesheet" type="text/css" href="bootstrap.min.css" />
    <link rel="stylesheet" type="text/css" href="apidocs.css" />
    <link rel="stylesheet" type="text/css" href="extra.css" />
</head>

  <body>

    <div id="banner">    
    <div>
        <a href="/">Home</a>
        &gt; scrapy-2.6.1 <!-- This is a placeholder -->
        
        <!-- (<a href=""&gt;show all versions</a&gt;) -->
    </div>
</div>

    <nav class="navbar navbar-default">
  
  <div class="container">

    <div class="navbar-header">
      
      <div class="navlinks">
        <span class="navbar-brand">
          scrapy <a href="index.html">API Documentation</a>
        </span>

        <a href="moduleIndex.html">
          Modules
        </a>

        <a href="classIndex.html">
          Classes
        </a>

        <a href="nameIndex.html">
          Names
        </a>

        <div id="search-box-container">
          <div class="input-group">
            <input id="search-box" type="search" name="search-query" placeholder="Search..." aria-label="Search" minlength="2" class="form-control" autocomplete="off" />
            
            <span class="input-group-btn">
              <a style="display: none;" class="btn btn-default" id="search-clear-button" title="Clear" onclick="clearSearch()"><img src="fonts/x-circle.svg" alt="Clear" /></a>
              <a class="btn btn-default" id="search-help-button" title="Help" onclick="toggleSearchHelpText()"><img src="fonts/info.svg" alt="Help" /></a>
            </span>
          </div>
        </div>

      </div>

      <div id="search-results-container" style="display: none;">
        <noscript>
            <h1>Cannot search: JavaScript is not supported/enabled in your browser.</h1>
        </noscript>

        <div class="hint" id="search-help-box">
          <p class="rst-last">
      
            Search bar offers the following options:
            <ul>   
                <li>
                  <strong>Term presence.</strong> The below example searches for documents that 
                    must contain “foo”, might contain “bar” and must not contain “baz”: <code>+foo bar -baz</code>
                </li> 

                <li>
                  <strong>Wildcards.</strong> The below example searches for documents with words beginning with “foo”: <code>foo*</code>
                </li> 

                <li>
                  <strong>Search in specific fields.</strong> The following search matches all documents 
                  that contains "foo" in their full dotted name and with “bar” in any field: <code>+fullName:*foo* +bar</code>

                  <p>
                    Possible fields: 'name', 'docstring', 'fullName'.
                  </p>
                </li>

                <li>
                  <strong>Fuzzy matches.</strong> The following search matches all documents 
                  that have a word within 1 edit distance of “foo”: <code>foo~1</code>
                </li>
            </ul>

          </p>
        </div>

        <div id="search-status"> </div>
        
        <div class="warning" id="search-warn-box" style="display: none;">
          <p class="rst-last"><span id="search-warn"></span></p>
        </div>

        <table id="search-results">
          <!-- Filled dynamically by JS -->
        </table>
        
        <div>
          <br />
          <p>Results provided by <a href="https://lunrjs.com">Lunr.js</a></p>
        </div>
      </div>

    </div>
  </div>

  <script src="ajax.js" type="text/javascript"></script>
  <script src="search.js" type="text/javascript"></script>

</nav>

    

    <div class="container">

      <div class="page-header">
        <h1 class="class"><code><code><a href="index.html" class="internal-link">scrapy</a></code><wbr></wbr>.<code><a href="scrapy.robotstxt.html" class="internal-link" title="scrapy.robotstxt">robotstxt</a></code><wbr></wbr>.<code><a href="scrapy.robotstxt.RerpRobotParser.html" class="internal-link" title="scrapy.robotstxt.RerpRobotParser">RerpRobotParser</a></code></code></h1>
        <div id="showPrivate">
          <button class="btn btn-link" onclick="togglePrivate()">Toggle Private API</button>
        </div>
      </div>

      <div class="categoryHeader">
        class documentation
      </div>

      <div class="extrasDocstring">
        <p><code><span class="py-keyword">class</span> <span class="py-defname">RerpRobotParser</span>(<a href="scrapy.robotstxt.RobotParser.html" class="internal-link" title="scrapy.robotstxt.RobotParser">RobotParser</a>): <a href="https://github.com/pydocbrowser/pydocbrowser.github.io/tree/main/build/sources/scrapy-2.6.1//scrapy/robotstxt.py#L94" class="sourceLink">(source)</a></code></p>
        <p><a href="classIndex.html#scrapy.robotstxt.RerpRobotParser">View In Hierarchy</a></p>
      </div>

      <div class="moduleDocstring">
        <div><p class="undocumented">Undocumented</p></div>
      </div>

      <div id="splitTables">
        <table class="children sortable" id="id6029">
  
  
  <tr class="classmethod">
    
    <td>Class Method</td>
    <td><code><a href="#from_crawler" class="internal-link" title="scrapy.robotstxt.RerpRobotParser.from_crawler">from​_crawler</a></code></td>
    <td>Parse the content of a robots.txt_ file as bytes. This must be a class method. It must return a new instance of the parser backend.</td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#__init__" class="internal-link" title="scrapy.robotstxt.RerpRobotParser.__init__">__init__</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="method">
    
    <td>Method</td>
    <td><code><a href="#allowed" class="internal-link" title="scrapy.robotstxt.RerpRobotParser.allowed">allowed</a></code></td>
    <td>Return ``True`` if  ``user_agent`` is allowed to crawl ``url``, otherwise return ``False``.</td>
  </tr><tr class="instancevariable">
    
    <td>Instance Variable</td>
    <td><code><a href="#rp" class="internal-link" title="scrapy.robotstxt.RerpRobotParser.rp">rp</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="instancevariable">
    
    <td>Instance Variable</td>
    <td><code><a href="#spider" class="internal-link" title="scrapy.robotstxt.RerpRobotParser.spider">spider</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr>
</table>
        

          
      </div>

      <div id="childList">

        <div class="baseclassmethod">
  
  
  <a name="scrapy.robotstxt.RerpRobotParser.from_crawler">
    
  </a>
  <a name="from_crawler">
    
  </a>
  <div class="functionHeader">
    @<a href="https://docs.python.org/3/library/functions.html#classmethod" class="intersphinx-link">classmethod</a><br />
    <span class="py-keyword">def</span> <span class="py-defname">from_crawler</span>(cls, crawler, robotstxt_body):
    <a class="sourceLink" href="https://github.com/pydocbrowser/pydocbrowser.github.io/tree/main/build/sources/scrapy-2.6.1//scrapy/robotstxt.py#L102">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    <div class="interfaceinfo">overrides <code><a href="scrapy.robotstxt.RobotParser.html#from_crawler" class="internal-link">scrapy.robotstxt.RobotParser.from_crawler</a></code></div>
    
    <div><p>Parse the content of a robots.txt_ file as bytes. This must be a class method. It must return a new instance of the parser backend.</p>
<p>:param crawler: crawler which made the request :type crawler: :class:`~scrapy.crawler.Crawler` instance</p>
<p>:param robotstxt_body: content of a robots.txt_ file. :type robotstxt_body: bytes</p>
</div>
  </div>
</div><div class="basemethod">
  
  
  <a name="scrapy.robotstxt.RerpRobotParser.__init__">
    
  </a>
  <a name="__init__">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">__init__</span>(self, robotstxt_body, spider):
    <a class="sourceLink" href="https://github.com/pydocbrowser/pydocbrowser.github.io/tree/main/build/sources/scrapy-2.6.1//scrapy/robotstxt.py#L95">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basemethod">
  
  
  <a name="scrapy.robotstxt.RerpRobotParser.allowed">
    
  </a>
  <a name="allowed">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">allowed</span>(self, url, user_agent):
    <a class="sourceLink" href="https://github.com/pydocbrowser/pydocbrowser.github.io/tree/main/build/sources/scrapy-2.6.1//scrapy/robotstxt.py#L108">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    <div class="interfaceinfo">overrides <code><a href="scrapy.robotstxt.RobotParser.html#allowed" class="internal-link">scrapy.robotstxt.RobotParser.allowed</a></code></div>
    
    <div><p>Return ``True`` if  ``user_agent`` is allowed to crawl ``url``, otherwise return ``False``.</p>
<p>:param url: Absolute URL :type url: str</p>
<p>:param user_agent: User agent :type user_agent: str</p>
</div>
  </div>
</div><div class="baseinstancevariable">
  
  
  <a name="scrapy.robotstxt.RerpRobotParser.rp">
    
  </a>
  <a name="rp">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">rp</span> =
    <a class="sourceLink" href="https://github.com/pydocbrowser/pydocbrowser.github.io/tree/main/build/sources/scrapy-2.6.1//scrapy/robotstxt.py#L98">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
    
  </div>
</div><div class="baseinstancevariable">
  
  
  <a name="scrapy.robotstxt.RerpRobotParser.spider">
    
  </a>
  <a name="spider">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-defname">spider</span> =
    <a class="sourceLink" href="https://github.com/pydocbrowser/pydocbrowser.github.io/tree/main/build/sources/scrapy-2.6.1//scrapy/robotstxt.py#L97">
      
      (source)
    </a>
  </div>
  <div class="functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
    
  </div>
</div>

      </div>
    </div>

    <footer class="navbar navbar-default">
  
  <div class="container">
    <a href="index.html">API Documentation</a> for scrapy,
  generated by <a href="https://github.com/twisted/pydoctor/">pydoctor</a>
    22.2.2.dev0 at 2022-03-02 23:24:14.
  </div>
</footer>

    <script src="pydoctor.js" type="text/javascript"></script>

  </body>
</html>