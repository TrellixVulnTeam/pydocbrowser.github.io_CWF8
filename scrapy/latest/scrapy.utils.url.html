<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
          "DTD/xhtml1-strict.dtd">
<html>
  

  <head>
    
    <title>scrapy.utils.url</title>
    <meta name="generator" content="pydoctor 22.2.0"> 
        
    </meta>
    <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=0.75" />
    <link rel="stylesheet" type="text/css" href="bootstrap.min.css" />
    <link rel="stylesheet" type="text/css" href="apidocs.css" />
    <link rel="stylesheet" type="text/css" href="extra.css" />
</head>

  <body>

    <div id="banner" class="container">    
    <div>
        <a href="https://pydocbrowser.github.io/">Home</a>
        &gt; scrapy-2.5.1 
        <!-- This is an important placeholder and will be 
            replaced by project name and version on building docs -->
        
        <!-- (<a href=""&gt;show all versions</a&gt;) -->
    </div>
</div>

    <nav class="navbar navbar-default">
  
  <div class="container">

    <div class="navbar-header">
      
      <div class="navlinks">
          <span class="navbar-brand">
            scrapy <a href="index.html">API Documentation</a>
          </span>

          <a href="moduleIndex.html">
            Modules
          </a>

          <a href="classIndex.html">
            Classes
          </a>

          <a href="nameIndex.html">
            Names
          </a>
      </div>

    </div>
  </div>
</nav>

    

    <div class="container">

      <div class="page-header">
        <h1 class="module"><code><code><a href="index.html" class="internal-link">scrapy</a></code><wbr></wbr>.<code><a href="scrapy.utils.html" class="internal-link" title="scrapy.utils">utils</a></code><wbr></wbr>.<code><a href="scrapy.utils.url.html" class="internal-link" title="scrapy.utils.url">url</a></code></code></h1>
        <div id="showPrivate">
          <button class="btn btn-link" onclick="togglePrivate()">Toggle Private API</button>
        </div>
      </div>

      <div class="categoryHeader">
        module documentation
      </div>

      <div class="extrasDocstring">
        <a href="https://github.com/pydocbrowser/pydocbrowser.github.io/tree/main/build/sources/scrapy-2.5.1//scrapy/utils/url.py" class="sourceLink">(source)</a>
        <p></p>
      </div>

      <div class="moduleDocstring">
        <div><p>This module contains general purpose URL functions not found in the standard
library.</p>
<p>Some of the functions that used to be imported from this module have been moved
to the w3lib.url module. Always import those from there instead.</p>
</div>
      </div>

      <div id="splitTables">
        <table class="children sortable" id="id15703">
  
  
  <tr class="function">
    
    <td>Function</td>
    <td><code><a href="#add_http_if_no_scheme" class="internal-link" title="scrapy.utils.url.add_http_if_no_scheme">add​_http​_if​_no​_scheme</a></code></td>
    <td>Add http as the default scheme if it is missing from the url.</td>
  </tr><tr class="function">
    
    <td>Function</td>
    <td><code><a href="#escape_ajax" class="internal-link" title="scrapy.utils.url.escape_ajax">escape​_ajax</a></code></td>
    <td>Return the crawleable url according to: <a class="rst-reference external" href="https://developers.google.com/webmasters/ajax-crawling/docs/getting-started" target="_top">https://developers.google.com/webmasters/ajax-crawling/docs/getting-started</a></td>
  </tr><tr class="function">
    
    <td>Function</td>
    <td><code><a href="#guess_scheme" class="internal-link" title="scrapy.utils.url.guess_scheme">guess​_scheme</a></code></td>
    <td>Add an URL scheme if missing: <a class="rst-reference external" href="file://" target="_top">file://</a> for filepath-like input or <a class="rst-reference external" href="http://" target="_top">http://</a> otherwise.</td>
  </tr><tr class="function">
    
    <td>Function</td>
    <td><code><a href="#parse_url" class="internal-link" title="scrapy.utils.url.parse_url">parse​_url</a></code></td>
    <td>Return urlparsed url from the given argument (which could be an already parsed url)</td>
  </tr><tr class="function">
    
    <td>Function</td>
    <td><code><a href="#strip_url" class="internal-link" title="scrapy.utils.url.strip_url">strip​_url</a></code></td>
    <td>Strip URL string from some of its components:</td>
  </tr><tr class="function">
    
    <td>Function</td>
    <td><code><a href="#url_has_any_extension" class="internal-link" title="scrapy.utils.url.url_has_any_extension">url​_has​_any​_extension</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="function">
    
    <td>Function</td>
    <td><code><a href="#url_is_from_any_domain" class="internal-link" title="scrapy.utils.url.url_is_from_any_domain">url​_is​_from​_any​_domain</a></code></td>
    <td>Return True if the url belongs to any of the given domains</td>
  </tr><tr class="function">
    
    <td>Function</td>
    <td><code><a href="#url_is_from_spider" class="internal-link" title="scrapy.utils.url.url_is_from_spider">url​_is​_from​_spider</a></code></td>
    <td>Return True if the url belongs to the given spider</td>
  </tr><tr class="function private">
    
    <td>Function</td>
    <td><code><a href="#_is_filesystem_path" class="internal-link" title="scrapy.utils.url._is_filesystem_path">​_is​_filesystem​_path</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="function private">
    
    <td>Function</td>
    <td><code><a href="#_is_posix_path" class="internal-link" title="scrapy.utils.url._is_posix_path">​_is​_posix​_path</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr><tr class="function private">
    
    <td>Function</td>
    <td><code><a href="#_is_windows_path" class="internal-link" title="scrapy.utils.url._is_windows_path">​_is​_windows​_path</a></code></td>
    <td><span class="undocumented">Undocumented</span></td>
  </tr>
</table>
        

          
      </div>

      <div id="childList">

        <div class="basefunction">
  
  
  <a name="scrapy.utils.url.add_http_if_no_scheme">
    
  </a>
  <a name="add_http_if_no_scheme">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">add_http_if_no_scheme</span>(url):
    <a class="sourceLink" href="https://github.com/pydocbrowser/pydocbrowser.github.io/tree/main/build/sources/scrapy-2.5.1//scrapy/utils/url.py#L75">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Add http as the default scheme if it is missing from the url.</div>
  </div>
</div><div class="basefunction">
  
  
  <a name="scrapy.utils.url.escape_ajax">
    
  </a>
  <a name="escape_ajax">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">escape_ajax</span>(url):
    <a class="sourceLink" href="https://github.com/pydocbrowser/pydocbrowser.github.io/tree/main/build/sources/scrapy-2.5.1//scrapy/utils/url.py#L46">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p>Return the crawleable url according to:
<a class="rst-reference external" href="https://developers.google.com/webmasters/ajax-crawling/docs/getting-started" target="_top">https://developers.google.com/webmasters/ajax-crawling/docs/getting-started</a></p>
<pre class="py-doctest">
<span class="py-prompt">&gt;&gt;&gt; </span>escape_ajax(<span class="py-string">"www.example.com/ajax.html#!key=value"</span>)
<span class="py-output">'www.example.com/ajax.html?_escaped_fragment_=key%3Dvalue'</span>
<span class="py-prompt">&gt;&gt;&gt; </span>escape_ajax(<span class="py-string">"www.example.com/ajax.html?k1=v1&amp;k2=v2#!key=value"</span>)
<span class="py-output">'www.example.com/ajax.html?k1=v1&amp;k2=v2&amp;_escaped_fragment_=key%3Dvalue'</span>
<span class="py-prompt">&gt;&gt;&gt; </span>escape_ajax(<span class="py-string">"www.example.com/ajax.html?#!key=value"</span>)
<span class="py-output">'www.example.com/ajax.html?_escaped_fragment_=key%3Dvalue'</span>
<span class="py-prompt">&gt;&gt;&gt; </span>escape_ajax(<span class="py-string">"www.example.com/ajax.html#!"</span>)
<span class="py-output">'www.example.com/ajax.html?_escaped_fragment_='</span>
</pre><p>URLs that are not "AJAX crawlable" (according to Google) returned as-is:</p>
<pre class="py-doctest">
<span class="py-prompt">&gt;&gt;&gt; </span>escape_ajax(<span class="py-string">"www.example.com/ajax.html#key=value"</span>)
<span class="py-output">'www.example.com/ajax.html#key=value'</span>
<span class="py-prompt">&gt;&gt;&gt; </span>escape_ajax(<span class="py-string">"www.example.com/ajax.html#"</span>)
<span class="py-output">'www.example.com/ajax.html#'</span>
<span class="py-prompt">&gt;&gt;&gt; </span>escape_ajax(<span class="py-string">"www.example.com/ajax.html"</span>)
<span class="py-output">'www.example.com/ajax.html'</span>
</pre></div>
  </div>
</div><div class="basefunction">
  
  
  <a name="scrapy.utils.url.guess_scheme">
    
  </a>
  <a name="guess_scheme">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">guess_scheme</span>(url):
    <a class="sourceLink" href="https://github.com/pydocbrowser/pydocbrowser.github.io/tree/main/build/sources/scrapy-2.5.1//scrapy/utils/url.py#L128">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Add an URL scheme if missing: <a class="rst-reference external" href="file://" target="_top">file://</a> for filepath-like input or
<a class="rst-reference external" href="http://" target="_top">http://</a> otherwise.</div>
  </div>
</div><div class="basefunction">
  
  
  <a name="scrapy.utils.url.parse_url">
    
  </a>
  <a name="parse_url">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">parse_url</span>(url, encoding=<a href="https://docs.python.org/3/library/constants.html#None" class="intersphinx-link">None</a>):
    <a class="sourceLink" href="https://github.com/pydocbrowser/pydocbrowser.github.io/tree/main/build/sources/scrapy-2.5.1//scrapy/utils/url.py#L37">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Return urlparsed url from the given argument (which could be an already
parsed url)</div>
  </div>
</div><div class="basefunction">
  
  
  <a name="scrapy.utils.url.strip_url">
    
  </a>
  <a name="strip_url">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">strip_url</span>(url, strip_credentials=<a href="https://docs.python.org/3/library/constants.html#True" class="intersphinx-link">True</a>, strip_default_port=<a href="https://docs.python.org/3/library/constants.html#True" class="intersphinx-link">True</a>, origin_only=<a href="https://docs.python.org/3/library/constants.html#False" class="intersphinx-link">False</a>, strip_fragment=<a href="https://docs.python.org/3/library/constants.html#True" class="intersphinx-link">True</a>):
    <a class="sourceLink" href="https://github.com/pydocbrowser/pydocbrowser.github.io/tree/main/build/sources/scrapy-2.5.1//scrapy/utils/url.py#L136">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p>Strip URL string from some of its components:</p>
<ul class="rst-simple">
<li><tt class="rst-docutils literal">strip_credentials</tt> removes "user:password@"</li>
<li><tt class="rst-docutils literal">strip_default_port</tt> removes ":80" (resp. ":443", ":21")
from <a class="rst-reference external" href="http://" target="_top">http://</a> (resp. <a class="rst-reference external" href="https://" target="_top">https://</a>, <a class="rst-reference external" href="ftp://" target="_top">ftp://</a>) URLs</li>
<li><tt class="rst-docutils literal">origin_only</tt> replaces path component with "/", also dropping
query and fragment components ; it also strips credentials</li>
<li><tt class="rst-docutils literal">strip_fragment</tt> drops any #fragment component</li>
</ul>
</div>
  </div>
</div><div class="basefunction">
  
  
  <a name="scrapy.utils.url.url_has_any_extension">
    
  </a>
  <a name="url_has_any_extension">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">url_has_any_extension</span>(url, extensions):
    <a class="sourceLink" href="https://github.com/pydocbrowser/pydocbrowser.github.io/tree/main/build/sources/scrapy-2.5.1//scrapy/utils/url.py#L33">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basefunction">
  
  
  <a name="scrapy.utils.url.url_is_from_any_domain">
    
  </a>
  <a name="url_is_from_any_domain">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">url_is_from_any_domain</span>(url, domains):
    <a class="sourceLink" href="https://github.com/pydocbrowser/pydocbrowser.github.io/tree/main/build/sources/scrapy-2.5.1//scrapy/utils/url.py#L19">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Return True if the url belongs to any of the given domains</div>
  </div>
</div><div class="basefunction">
  
  
  <a name="scrapy.utils.url.url_is_from_spider">
    
  </a>
  <a name="url_is_from_spider">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">url_is_from_spider</span>(url, spider):
    <a class="sourceLink" href="https://github.com/pydocbrowser/pydocbrowser.github.io/tree/main/build/sources/scrapy-2.5.1//scrapy/utils/url.py#L28">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div>Return True if the url belongs to the given spider</div>
  </div>
</div><div class="basefunction private">
  
  
  <a name="scrapy.utils.url._is_filesystem_path">
    
  </a>
  <a name="_is_filesystem_path">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_is_filesystem_path</span>(string):
    <a class="sourceLink" href="https://github.com/pydocbrowser/pydocbrowser.github.io/tree/main/build/sources/scrapy-2.5.1//scrapy/utils/url.py#L124">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basefunction private">
  
  
  <a name="scrapy.utils.url._is_posix_path">
    
  </a>
  <a name="_is_posix_path">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_is_posix_path</span>(string):
    <a class="sourceLink" href="https://github.com/pydocbrowser/pydocbrowser.github.io/tree/main/build/sources/scrapy-2.5.1//scrapy/utils/url.py#L86">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div><div class="basefunction private">
  
  
  <a name="scrapy.utils.url._is_windows_path">
    
  </a>
  <a name="_is_windows_path">
    
  </a>
  <div class="functionHeader">
    
    <span class="py-keyword">def</span> <span class="py-defname">_is_windows_path</span>(string):
    <a class="sourceLink" href="https://github.com/pydocbrowser/pydocbrowser.github.io/tree/main/build/sources/scrapy-2.5.1//scrapy/utils/url.py#L108">
      
      (source)
    </a>
  </div>
  <div class="docstring functionBody">
    
    
    <div><p class="undocumented">Undocumented</p></div>
  </div>
</div>

      </div>
    </div>

    <footer class="navbar navbar-default">
  
  <div class="container">
    <a href="index.html">API Documentation</a> for scrapy,
  generated by <a href="https://github.com/twisted/pydoctor/">pydoctor</a>
    22.2.0 at 2022-02-23 08:19:51.
  </div>
</footer>

    <script src="pydoctor.js" type="text/javascript"></script>

  </body>
</html>